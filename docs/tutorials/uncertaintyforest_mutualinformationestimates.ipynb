{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the UncertaintyForest Class by Reproducing Mutual Information Estimates\n",
    "\n",
    "This set of four tutorials (`uncertaintyforest_running_example.ipynb`,`uncertaintyforest_posteriorestimates.ipynb`, `uncertaintyforest_conditionalentropyestimates.ipynb`, and `uncertaintyforest_mutualinformationestimates.ipynb`) will explain the UncertaintyForest class. After following these tutorials, you should have the ability to run UncertaintyForest on your own machine and generate Figures 1, 2, and 3 from [this paper](https://arxiv.org/pdf/1907.00325.pdf), which help you to visualize a comparison of the estimated posteriors and conditional entropy values for several different algorithms. \n",
    "\n",
    "If you haven't seen it already, take a look at other tutorials to setup and install the ProgLearn package: `installation_guide.ipynb`.\n",
    "\n",
    "*Goal: Run the UncertaintyForest class to produce a figure that compares estimated normalized mutual information values for the UncertaintyForest, KSG, Mixed KSG, and IRF algorithms, as in Figure 3 from [this paper](https://arxiv.org/pdf/1907.00325.pdf)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (mixed.py, line 56)",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/eyezerets/uf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3296\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-c167dfe37100>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    import mixed\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/eyezerets/uf/lib/python3.8/site-packages/mixed.py\"\u001b[0;36m, line \u001b[0;32m56\u001b[0m\n\u001b[0;31m    raise TypeError, 'Could not interpret as mixed number'\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from proglearn.forest import UncertaintyForest\n",
    "from functions.unc_forest_tutorials_functions import generate_data_fig3, _make_params, _make_three_class_params, plot_setting, compute_mutual_info, estimate_mi, get_plot_mutual_info_by_pi, get_plot_mutual_info_by_d, plot_fig3\n",
    "\n",
    "# import os,sys,inspect\n",
    "# current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "# parent_dir = os.path.dirname(current_dir)\n",
    "# sys.path.insert(0, parent_dir) \n",
    "import mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting figures.\n",
    "settings = [\n",
    "    {\n",
    "        'name' : 'Spherical Gaussians',\n",
    "        'kwargs': {},\n",
    "        'filename' : 'spherical'\n",
    "    },\n",
    "    {\n",
    "        'name' : 'Elliptical Gaussians',\n",
    "        'kwargs': {'var1' : 3},\n",
    "        'filename' : 'ellyptical'\n",
    "    },\n",
    "    {\n",
    "        'name' : 'Three Class Gaussians',\n",
    "        'kwargs': {'three_class' : True},\n",
    "        'filename' : 'three_class'\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data.\n",
    "fig, axes = plt.subplots(1, len(settings), figsize = (18,4))\n",
    "for i, setting in enumerate(settings):\n",
    "    plot_setting(2000, setting, axes[i])\n",
    "    \n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following are two sets of parameters.\n",
    "# The first are those that were actually used to produce Figure 3.\n",
    "# Below those, you'll find some testing parameters so that you can see the results more quickly.\n",
    "\n",
    "# Here are the \"Real Parameters\"\n",
    "# n = 6000\n",
    "# mus = range(5)\n",
    "# ds = range(1, 16)\n",
    "# mu = 1\n",
    "# num_trials = 20\n",
    "# d = 2\n",
    "# pis = [0.05 * i for i in range(1, 20)]\n",
    "\n",
    "# Here are the \"Test Parameters\"\n",
    "n = 400 # number of samples\n",
    "mus = range(3) # range of means\n",
    "ds = range(2, 5) # range of dimensions\n",
    "mu = 1 # mean\n",
    "num_trials = 3 # number of trials to run\n",
    "d = 1 # dimension\n",
    "pis = [0.05 * i for i in range(3, 6)] # prior distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Learners\n",
    "Now, we'll specify which learners we'll compare (by label). Figure 3 uses four different learners, which are further specified in the function `estimate_mi`, which returns estimates of mutual information for a given dataset (X, y) and type of learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithms used to produce Figure 3\n",
    "algos = [\n",
    "    {\n",
    "        'label': 'IRF',\n",
    "        'title': 'Isotonic Reg. Forest',\n",
    "        'color': \"#fdae61\",\n",
    "    },\n",
    "    {\n",
    "        'label': 'KSG',\n",
    "        'title': 'KSG',\n",
    "        'color': \"#1b9e77\",\n",
    "    },\n",
    "    {\n",
    "        'label': 'Mixed KSG',\n",
    "        'title': 'Mixed KSG',\n",
    "        'color': \"purple\",\n",
    "    },\n",
    "    {\n",
    "        'label': 'UF',\n",
    "        'title': 'Uncertainty Forest',\n",
    "        'color': \"#F41711\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for setting in settings:\n",
    "    # compute_truth_mu(d, mus, setting)\n",
    "    compute_truth_pi(d, pis, setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for setting in settings:\n",
    "#     get_mutual_info_vs_pi(n, d, pis, num_trials, algos, setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for setting in settings:\n",
    "#     get_mutual_info_vs_d(n, ds, num_trials, mu, algos, setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Figure 3\n",
    "\n",
    "Finally, we'll run the code to obtain and plot the spherical, elliptical, and three class Gaussians, as well as estimated mutual information vs. class priors and dimensionality (9 subplots)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fig3(algos, n, d, mu, settings, pis, ds, num_trials)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "11ddca5089527d17826da45cd024a0d3d3b64d2c1b5dbf54dd1c238d51a17f38"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}